{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7919f83",
   "metadata": {},
   "source": [
    "# Transaction Risk Classification Project\n",
    "\n",
    "This notebook processes transaction and alert data to classify transactions into risk groups based on sender/receiver patterns and transaction amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834afa8e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead03bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'write_connection_file' could not be imported from '/Users/miaparker/Library/Python/3.11/lib/python/site-packages/jupyter_client/__init__.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5f71a",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Alerts Data\n",
    "- Extract `days_old` and `time` from `age_of_alert`\n",
    "- Remove rows with missing `days_old`\n",
    "- Filter alerts older than 30 days and drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = pd.read_csv('exported_exported_34.csv', sep=';')\n",
    "alerts[['days_old', 'time']] = alerts['age_of_alert'].str.extract(r'(\\d+)\\s+days,\\s+([\\d:.]+)')\n",
    "alerts = alerts.dropna(subset=['days_old'])\n",
    "alerts['days_old'] = alerts['days_old'].astype(int)\n",
    "alerts = alerts[alerts['days_old'] > 30]\n",
    "alerts = alerts.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc3506",
   "metadata": {},
   "source": [
    "## 3. Load and Clean Transaction Data\n",
    "- Drop empty columns and rows with missing `STATE`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran = pd.read_csv('exported_exported_35.csv', sep=',')\n",
    "tran = tran.dropna(axis=1, how='all')\n",
    "tran = tran[tran['STATE'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412a8d9",
   "metadata": {},
   "source": [
    "## 4. Explode Alert Transaction IDs\n",
    "- Split `external_transaction_ids` by comma and explode to one row per tx_id\n",
    "- Convert `tx_id` to integer for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts['tx_id'] = alerts['external_transaction_ids'].str.split(r',\\s*')\n",
    "alerts = alerts.explode('tx_id').reset_index(drop=True)\n",
    "alerts['tx_id'] = alerts['tx_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de07fe",
   "metadata": {},
   "source": [
    "## 5. Merge Alerts with Transactions and Process Datetime\n",
    "- Merge on `tx_id` and `rule_code`\n",
    "- Drop duplicates\n",
    "- Extract day of the week from transaction datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = alerts.merge(\n",
    "    tran,\n",
    "    how='left',\n",
    "    left_on=['tx_id', 'rule_code'],\n",
    "    right_on=['tx_id', 'CHECKS']\n",
    ")\n",
    "all_data = all_data.drop_duplicates()\n",
    "all_data['tx_date_time'] = pd.to_datetime(all_data['tx_date_time'])\n",
    "all_data['day_of_week'] = all_data['tx_date_time'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb8639",
   "metadata": {},
   "source": [
    "## 6. Clean Sender Names and Create Business IDs\n",
    "- Standardize sender names to lowercase and stripped\n",
    "- Assign unique numeric `business_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['cleaned_sender_name'] = all_data['customer_name'].str.strip().str.lower().str.replace(',', '', regex=False)\n",
    "all_data['business_id'] = all_data['cleaned_sender_name'].astype('category').cat.codes + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b146f7",
   "metadata": {},
   "source": [
    "## 7. Step 1: Dataset of Not Suspicious / Soft Stop Transactions\n",
    "- Group by sender and counterparty\n",
    "- Compute count, median amount, MAD, and mode day of week\n",
    "- Only include counterparty with >2 transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_s = all_data[(all_data['ACTIONS'] == 'Soft Stop') & (all_data['STATE'] == 'Not Suspicious')]\n",
    "step_1_summary_dict = {}\n",
    "\n",
    "for sender in n_s['cleaned_sender_name'].unique():\n",
    "    info = n_s[n_s['cleaned_sender_name'] == sender]\n",
    "    step_1_summary = info.groupby('counterparty_name').agg(\n",
    "        count=('tx_base_amount', 'count'),\n",
    "        avg_amount=('tx_base_amount', 'median'),\n",
    "        std_amount=('tx_base_amount', lambda x: np.median(np.abs(x - np.median(x)))),\n",
    "        avg_day_of_week=('day_of_week', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    ).reset_index()\n",
    "    step_1_summary = step_1_summary[step_1_summary['count'] > 2]\n",
    "    step_1_summary_dict[sender] = step_1_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3c283",
   "metadata": {},
   "source": [
    "## 8. Step 2: Receiver-based Summary\n",
    "- Similar to step 1 but grouped by counterparty only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_2_summary = n_s.groupby('counterparty_name').agg(\n",
    "    count=('tx_base_amount', 'count'),\n",
    "    avg_amount=('tx_base_amount', 'median'),\n",
    "    std_amount=('tx_base_amount', lambda x: np.median(np.abs(x - np.median(x)))),\n",
    "    avg_day_of_week=('day_of_week', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    ").reset_index()\n",
    "step_2_summary = step_2_summary[step_2_summary['count'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a001270e",
   "metadata": {},
   "source": [
    "## 9. Identify In-Review Soft Stop Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee493dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_r = all_data[(all_data['status'] == 'In Review') & (all_data['ACTIONS'] == 'Soft Stop')]\n",
    "group_1 = []\n",
    "group_2 = []\n",
    "group_3 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b86fec",
   "metadata": {},
   "source": [
    "## 10. Define Risk Classification Function\n",
    "- Step 1: Sender-based check\n",
    "- Step 2: Receiver-based check\n",
    "- Step 3: Assign to group 3 if all else fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59990f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(row):\n",
    "    sender = row['cleaned_sender_name']\n",
    "    receiver = row['counterparty_name']\n",
    "    amount = row['tx_base_amount']\n",
    "    day = row['day_of_week']\n",
    "    risk = 0\n",
    "\n",
    "    if sender in step_1_summary_dict:\n",
    "        sender_info = step_1_summary_dict[sender]\n",
    "        if receiver in sender_info['counterparty_name'].values:\n",
    "            receiver_row = sender_info[sender_info['counterparty_name'] == receiver]\n",
    "            median_amount = receiver_row['avg_amount'].values[0]\n",
    "            mad_amount = receiver_row['std_amount'].values[0]\n",
    "            mode_day = receiver_row['avg_day_of_week'].values[0]\n",
    "            amount_ok = amount < (median_amount + mad_amount)\n",
    "            day_ok = day == mode_day\n",
    "            if amount_ok and day_ok:\n",
    "                group_1.append(row.copy())\n",
    "                return\n",
    "            else:\n",
    "                risk += 1\n",
    "        else:\n",
    "            risk += 1\n",
    "    else:\n",
    "        risk += 1\n",
    "\n",
    "    if risk > 0 and receiver in step_2_summary['counterparty_name'].values:\n",
    "        receiver_row = step_2_summary[step_2_summary['counterparty_name'] == receiver]\n",
    "        median_amount = receiver_row['avg_amount'].values[0]\n",
    "        mad_amount = receiver_row['std_amount'].values[0]\n",
    "        mode_day = receiver_row['avg_day_of_week'].values[0]\n",
    "        amount_ok = amount < (median_amount + mad_amount)\n",
    "        day_ok = day == mode_day\n",
    "        if amount_ok and day_ok:\n",
    "            group_2.append(row.copy())\n",
    "            return\n",
    "        else:\n",
    "            risk += 1\n",
    "\n",
    "    group_3.append(row.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364779cf",
   "metadata": {},
   "source": [
    "## 11. Apply Risk Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_r.apply(risk, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63a91d",
   "metadata": {},
   "source": [
    "## 12. Combine Risk Groups into Single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c7987",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(group_1)\n",
    "df2 = pd.DataFrame(group_2)\n",
    "df3 = pd.DataFrame(group_3)\n",
    "\n",
    "df1['risk_group'] = 1\n",
    "df2['risk_group'] = 2\n",
    "df3['risk_group'] = 3\n",
    "\n",
    "all_tx = pd.concat([df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04696731",
   "metadata": {},
   "source": [
    "## 13. Classify Alerts Based on Risk Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbecbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_group_1 = []\n",
    "alert_group_2 = []\n",
    "alert_group_3 = []\n",
    "\n",
    "unique_alerts = all_tx['alert_id'].unique()\n",
    "\n",
    "for alert_id in unique_alerts:\n",
    "    alert_rows = all_tx[all_tx['alert_id'] == alert_id]\n",
    "    risk_groups = alert_rows['risk_group'].tolist()\n",
    "    if all(r == 1 for r in risk_groups):\n",
    "        alert_group_1.append(alert_id)\n",
    "    elif 3 in risk_groups:\n",
    "        alert_group_3.append(alert_id)\n",
    "    elif all(r in [1, 2] for r in risk_groups) and 2 in risk_groups:\n",
    "        alert_group_2.append(alert_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
